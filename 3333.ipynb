{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irhBchpA_q64",
        "outputId": "cca73786-4582-4ac0-b1ed-f460c7b59e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "القيم الناقصة:\n",
            " Customer_ID                              0\n",
            "Age                                      0\n",
            "Gender                                   0\n",
            "Income_Level                             0\n",
            "Marital_Status                           0\n",
            "Education_Level                          0\n",
            "Occupation                               0\n",
            "Location                                 0\n",
            "Purchase_Category                        0\n",
            "Purchase_Amount                          0\n",
            "Frequency_of_Purchase                    0\n",
            "Purchase_Channel                         0\n",
            "Brand_Loyalty                            0\n",
            "Product_Rating                           0\n",
            "Time_Spent_on_Product_Research(hours)    0\n",
            "Social_Media_Influence                   0\n",
            "Discount_Sensitivity                     0\n",
            "Return_Rate                              0\n",
            "Customer_Satisfaction                    0\n",
            "Engagement_with_Ads                      0\n",
            "Device_Used_for_Shopping                 0\n",
            "Payment_Method                           0\n",
            "Time_of_Purchase                         0\n",
            "Discount_Used                            0\n",
            "Customer_Loyalty_Program_Member          0\n",
            "Purchase_Intent                          0\n",
            "Shipping_Preference                      0\n",
            "Time_to_Decision                         0\n",
            "Churn                                    0\n",
            "dtype: int64\n",
            "\n",
            "نتايج Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        67\n",
            "           1       0.98      1.00      0.99       133\n",
            "\n",
            "    accuracy                           0.98       200\n",
            "   macro avg       0.99      0.98      0.98       200\n",
            "weighted avg       0.99      0.98      0.98       200\n",
            "\n",
            "\n",
            "نتايج Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        67\n",
            "           1       1.00      1.00      1.00       133\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n",
            "نتايج XGBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        67\n",
            "           1       1.00      1.00      1.00       133\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:27:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "أفضل إعدادات لـ Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "أفضل F1-Score: 1.0\n",
            "\n",
            "نتايج Random Forest المحسن:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        67\n",
            "           1       1.00      1.00      1.00       133\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n",
            "ملخص أداء النماذج:\n",
            "Logistic Regression:\n",
            "  Accuracy: 0.9850\n",
            "  Precision: 0.9779\n",
            "  Recall: 1.0000\n",
            "  F1-Score: 0.9888\n",
            "Random Forest:\n",
            "  Accuracy: 1.0000\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1-Score: 1.0000\n",
            "XGBoost:\n",
            "  Accuracy: 1.0000\n",
            "  Precision: 1.0000\n",
            "  Recall: 1.0000\n",
            "  F1-Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# استدعاء المكتبات اللي هنحتاجها\n",
        "import pandas as pd  # لتحميل وتحليل الداتا\n",
        "import numpy as np  # للعمليات الرياضية\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV  # لتقسيم الداتا وتحسين النماذج\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder  # لتظبيط الداتا\n",
        "from sklearn.linear_model import LogisticRegression  # نموذج بسيط\n",
        "from sklearn.ensemble import RandomForestClassifier  # نموذج قوي\n",
        "from xgboost import XGBClassifier  # نموذج متقدم\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report  # لقياس الأداء\n",
        "\n",
        "# الخطوة 1: تحميل الداتاسيت\n",
        "# لو بتستخدمي Google Colab، فعّلي السطرين دول الأول عشان ترفعي الملف\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "data = pd.read_csv('/content/Deep_clean.csv')  # تحميل ملف الداتا\n",
        "\n",
        "# الخطوة 2: إنشاء عمود الـ Churn\n",
        "# العميل هيسيب لو رضا العميل <= 4 أو مش في برنامج الولاء\n",
        "data['Churn'] = ((data['Customer_Satisfaction'] <= 4) | (data['Customer_Loyalty_Program_Member'] == False)).astype(int)\n",
        "\n",
        "# الخطوة 3: تحضير الداتا\n",
        "# التأكد من القيم الناقصة\n",
        "print(\"القيم الناقصة:\\n\", data.isnull().sum())\n",
        "# لو فيه قيم ناقصة، ممكن نعبيها، بس الداتاسيت نضيفة فما فيهاش مشاكل\n",
        "\n",
        "# تحديد الأعمدة النصية والرقمية\n",
        "categorical_cols = ['Gender', 'Income_Level', 'Marital_Status', 'Education_Level', 'Occupation',\n",
        "                    'Location', 'Purchase_Category', 'Purchase_Channel', 'Brand_Loyalty',\n",
        "                    'Social_Media_Influence', 'Discount_Sensitivity', 'Engagement_with_Ads',\n",
        "                    'Device_Used_for_Shopping', 'Payment_Method', 'Discount_Used',\n",
        "                    'Customer_Loyalty_Program_Member', 'Purchase_Intent', 'Shipping_Preference']\n",
        "numerical_cols = ['Age', 'Purchase_Amount', 'Frequency_of_Purchase', 'Product_Rating',\n",
        "                 'Time_Spent_on_Product_Research(hours)', 'Return_Rate', 'Customer_Satisfaction',\n",
        "                 'Time_to_Decision']\n",
        "\n",
        "# تحويل الأعمدة النصية لأرقام\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()  # أداة بتحوّل النصوص لأرقام\n",
        "    data[col] = le.fit_transform(data[col])  # تحويل العمود\n",
        "    label_encoders[col] = le  # حفظ الأداة لو احتجناها\n",
        "\n",
        "# تظبيط الأعمدة الرقمية (جعلها في نطاق موحد)\n",
        "scaler = StandardScaler()  # أداة لتظبيط الأرقام\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])  # تطبيق التظبيط\n",
        "\n",
        "# الخطوة 4: تحديد الـ Features (X) والـ Target (y)\n",
        "X = data.drop(['Customer_ID', 'Time_of_Purchase', 'Churn'], axis=1)  # إزالة الأعمدة اللي مش هنستخدمها\n",
        "y = data['Churn']  # الهدف (Churn)\n",
        "\n",
        "# الخطوة 5: تقسيم الداتا\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% تدريب، 20% اختبار\n",
        "\n",
        "# الخطوة 6: تدريب وتقييم النماذج\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),  # نموذج بسيط\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),  # نموذج قوي\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)  # نموذج متقدم\n",
        "}\n",
        "\n",
        "# قاموس لتخزين النتايج\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # تدريب النموذج\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # التنبؤ على داتا الاختبار\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # قياس الأداء\n",
        "    accuracy = accuracy_score(y_test, y_pred)  # الدقة\n",
        "    precision = precision_score(y_test, y_pred)  # الدقة في التنبؤ بالـ Churn\n",
        "    recall = recall_score(y_test, y_pred)  # القدرة على إيجاد الـ Churn\n",
        "    f1 = f1_score(y_test, y_pred)  # مزيج بين Precision و Recall\n",
        "\n",
        "    # تخزين النتايج\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1\n",
        "    }\n",
        "\n",
        "    # طباعة تقرير مفصل\n",
        "    print(f\"\\nنتايج {name}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# الخطوة 7: تحسين نموذج Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],  # عدد الأشجار\n",
        "    'max_depth': [10, 20, None],  # العمق\n",
        "    'min_samples_split': [2, 5]  # الحد الأدنى للتقسيم\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# أفضل الإعدادات\n",
        "print(\"\\nأفضل إعدادات لـ Random Forest:\", grid_search.best_params_)\n",
        "print(\"أفضل F1-Score:\", grid_search.best_score_)\n",
        "\n",
        "# تدريب النموذج المحسن\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "print(\"\\nنتايج Random Forest المحسن:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# الخطوة 8: تلخيص النتايج\n",
        "print(\"\\nملخص أداء النماذج:\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# كود عشان نعرف أهم العوامل (Feature Importance)\n",
        "importances = best_rf.feature_importances_\n",
        "feature_names = X.columns\n",
        "for name, importance in zip(feature_names, importances):\n",
        "    print(f\"{name}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC7fGlK6CPKl",
        "outputId": "bfbce846-62b7-4f4f-efe5-bb0f09224502"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age: 0.0222\n",
            "Gender: 0.0109\n",
            "Income_Level: 0.0039\n",
            "Marital_Status: 0.0111\n",
            "Education_Level: 0.0078\n",
            "Occupation: 0.0065\n",
            "Location: 0.0301\n",
            "Purchase_Category: 0.0205\n",
            "Purchase_Amount: 0.0339\n",
            "Frequency_of_Purchase: 0.0177\n",
            "Purchase_Channel: 0.0074\n",
            "Brand_Loyalty: 0.0116\n",
            "Product_Rating: 0.0091\n",
            "Time_Spent_on_Product_Research(hours): 0.0086\n",
            "Social_Media_Influence: 0.0090\n",
            "Discount_Sensitivity: 0.0067\n",
            "Return_Rate: 0.0072\n",
            "Customer_Satisfaction: 0.3116\n",
            "Engagement_with_Ads: 0.0063\n",
            "Device_Used_for_Shopping: 0.0082\n",
            "Payment_Method: 0.0137\n",
            "Discount_Used: 0.0045\n",
            "Customer_Loyalty_Program_Member: 0.3944\n",
            "Purchase_Intent: 0.0110\n",
            "Shipping_Preference: 0.0064\n",
            "Time_to_Decision: 0.0197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(best_rf, X, y, cv=5, scoring='f1')\n",
        "print(f\"Cross-Validation F1-Scores: {scores}\")\n",
        "print(f\"متوسط F1-Score: {scores.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvhj704CC9Jr",
        "outputId": "18040baf-beff-4c81-fdf7-643e578c1adf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation F1-Scores: [1. 1. 1. 1. 1.]\n",
            "متوسط F1-Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# حفظ نموذج Logistic Regression\n",
        "joblib.dump(models['Logistic Regression'], 'logistic_regression_model.pkl')\n",
        "\n",
        "# حفظ نموذج Random Forest (المحسن)\n",
        "joblib.dump(best_rf, 'random_forest_model.pkl')\n",
        "\n",
        "# حفظ نموذج XGBoost\n",
        "joblib.dump(models['XGBoost'], 'xgboost_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jhUs46cDxsV",
        "outputId": "29d5bc61-31b2-46fc-a85e-8a34328cbb74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgboost_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}